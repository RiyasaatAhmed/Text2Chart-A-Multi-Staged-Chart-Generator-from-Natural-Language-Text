{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vector (Individual-Y).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yPdGW9l4ure"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnaflCTx44W-"
      },
      "source": [
        "os.chdir(\"drive/My Drive/Thesis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS7Yh1ZL4K4r"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9qdgeZp4QAL"
      },
      "source": [
        "pre_model = KeyedVectors.load_word2vec_format('w2v/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_DWiDIa6qhG"
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rab0xDOnHdrP",
        "outputId": "60c71365-9d60-44fd-a02c-a6858acf4dd6"
      },
      "source": [
        "if 'hello' in pre_model:\n",
        "  print('Hello')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgcJn4Dv5Cw1"
      },
      "source": [
        "import json\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB3TdnI25PJM"
      },
      "source": [
        "raw_text = []\n",
        "raw_label = []\n",
        "with open('training.json') as f:\n",
        "  file = json.load(f)\n",
        "  f.close()\n",
        "for x in file:\n",
        "  raw_text.append(x['text'])\n",
        "  raw_label.append(x['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Lxf8SgKrOS"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plDp7Ulc6VTG"
      },
      "source": [
        "sequence_length = 100 # tune it to max 300\n",
        "\n",
        "def wv_input(text_list, label_list):\n",
        "  input_id_list = []\n",
        "  attention_mask_list = []\n",
        "  tag_list = []\n",
        "  for sentence, stripe in zip(text_list, label_list):\n",
        "    temp_token = []\n",
        "    temp_tag = []\n",
        "    temp_attention = []\n",
        "    temp_type = []\n",
        "    for word, tag in zip(sentence.split(), stripe):\n",
        "      if tag == 1:\n",
        "        tag = 0\n",
        "      elif tag == 2:\n",
        "        tag = 1\n",
        "      if word in string.punctuation:\n",
        "        continue\n",
        "     # print('here')\n",
        "      if word in pre_model:\n",
        "        new_token = [pre_model[word]]\n",
        "        new_label = [tag] \n",
        "        new_attention = [1]\n",
        "      else:\n",
        "        new_token = [np.array([-1.0 for i in range(300)])]\n",
        "        new_label = [tag]\n",
        "        new_attention = [1]\n",
        "      \n",
        "      temp_token.extend(new_token)\n",
        "      temp_tag.extend(new_label)\n",
        "      temp_attention.extend(new_attention)\n",
        "   ## print(np.shape(temp_token))\n",
        "   # print(temp_token)\n",
        "\n",
        "\n",
        "    if len(temp_token) < sequence_length:\n",
        "      extend_list = [[-1.00 for i in range(300)]] * (sequence_length - len(temp_token))\n",
        "      extend_tag = [2] * (sequence_length - len(temp_token))\n",
        "      temp_attention = temp_attention + [0] * (sequence_length - len(temp_token))\n",
        "      temp_token = temp_token + extend_list\n",
        "      temp_tag = temp_tag + extend_tag\n",
        "\n",
        "    elif len(temp_token) > sequence_length:\n",
        "      temp_token = temp_token[:sequence_length ]\n",
        "      temp_attention = temp_attention[:sequence_length]\n",
        "      temp_tag = temp_tag[:sequence_length]\n",
        "\n",
        "    input_id_list.append(temp_token)\n",
        "    attention_mask_list.append(temp_attention)\n",
        "    tag_list.append(temp_tag)\n",
        "\n",
        "  \n",
        "  \n",
        "  return np.array(input_id_list), np.array(attention_mask_list), np.array(tag_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-vWjObkLhSY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhcy2cv8KaLL"
      },
      "source": [
        "input_data, mask_data, output_data  = wv_input(raw_text, raw_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-cpuwPLKmMY",
        "outputId": "f9b77ab8-9d1e-4137-d909-ed3a607aa365"
      },
      "source": [
        "np.shape(input_data), np.shape(output_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((580, 100, 300), (580, 100))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-SQDZFJO_oS"
      },
      "source": [
        "train_data_x = np.array(input_data[:464])\n",
        "valid_data_x = np.array(input_data[464:])                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCmug7NFPPnB"
      },
      "source": [
        "train_data_y = np.array(output_data[:464]).reshape(464, -1, 1)\n",
        "valid_data_y = np.array(output_data[464:]).reshape(116, -1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INrU4rL3YKyl"
      },
      "source": [
        "train_mask = np.array(mask_data[:464])\n",
        "valid_mask = np.array(mask_data[464:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzgzzkA7RaJy"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEWfKWajRgUx"
      },
      "source": [
        "best = 0\n",
        "num_label = 3\n",
        "def see(ty, tp):\n",
        "  #model.load('')\n",
        "  ty = ty.reshape(-1)\n",
        "  tp = tp.reshape(-1, num_label)\n",
        "  #print(tp.shape, ty.shape)\n",
        "  tp = [np.argmax(x) for x in tp]\n",
        "  dix = np.where(ty == (num_label - 1))[0]\n",
        "  tp = np.delete(tp, dix)\n",
        "  ty = np.delete(ty, dix)\n",
        "  #valid_p = [1 if x > 0.5 else 0 for x in model.predict(valid_x)]\n",
        "  #valid_p = model.predict(valid_x)\n",
        " # print(np.shape(tp), ty.shape)\n",
        "  print('\\nClassification Report \\n\\n')\n",
        "  \n",
        "  f = classification_report(ty, tp)\n",
        "  print(f)\n",
        " # print('\\nPrint Confusion Matrix \\n\\n')\n",
        "  print(confusion_matrix(ty, tp))\n",
        "  return f1_score(ty, tp, average=None)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9piFpZqRjm5"
      },
      "source": [
        "class mcb(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, log=None):\n",
        "   # global train_x, train_y, valid_x, valid_y\n",
        "    print('here')\n",
        "    _y = self.model.predict(train_data_x)\n",
        "    see(train_data_y, _y)\n",
        "    _y = self.model.predict(valid_data_x)\n",
        "    see(valid_data_y, _y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qt1asEqRm0R"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.LSTM(units=512, return_sequences=True),\n",
        "                             tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
        "                             tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation='relu')),\n",
        "                             tf.keras.layers.Dense(1024, activation='relu'),\n",
        "                             tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjjHd5tsRrKl"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U23pbRxKRuGi",
        "outputId": "ba091f44-1fad-4480-fbe9-d8816e453748"
      },
      "source": [
        "model.fit(train_data_x, train_data_y, epochs=3,\n",
        "          validation_data=(valid_data_x, valid_data_y),\n",
        "          sample_weight=train_mask, callbacks=[mcb()],\n",
        "          batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "58/58 [==============================] - 61s 985ms/step - loss: 0.2022 - accuracy: 0.3614 - val_loss: 3.5701 - val_accuracy: 0.3747\n",
            "here\n",
            "(46400, 3) (46400,)\n",
            "(46400,) (46400,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      1.00      0.53     16860\n",
            "           1       0.00      0.00      0.00      2716\n",
            "           2       0.00      0.00      0.00     26824\n",
            "\n",
            "    accuracy                           0.36     46400\n",
            "   macro avg       0.12      0.33      0.18     46400\n",
            "weighted avg       0.13      0.36      0.19     46400\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[16860     0     0]\n",
            " [ 2716     0     0]\n",
            " [26824     0     0]]\n",
            "(11600, 3) (11600,)\n",
            "(11600,) (11600,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      1.00      0.55      4346\n",
            "           1       0.00      0.00      0.00       795\n",
            "           2       0.00      0.00      0.00      6459\n",
            "\n",
            "    accuracy                           0.37     11600\n",
            "   macro avg       0.12      0.33      0.18     11600\n",
            "weighted avg       0.14      0.37      0.20     11600\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[4346    0    0]\n",
            " [ 795    0    0]\n",
            " [6459    0    0]]\n",
            "Epoch 2/3\n",
            "58/58 [==============================] - 55s 946ms/step - loss: 0.0833 - accuracy: 0.3728 - val_loss: 4.6617 - val_accuracy: 0.3950\n",
            "here\n",
            "(46400, 3) (46400,)\n",
            "(46400,) (46400,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.86     16860\n",
            "           1       0.06      0.62      0.12      2716\n",
            "           2       0.00      0.00      0.00     26824\n",
            "\n",
            "    accuracy                           0.38     46400\n",
            "   macro avg       0.29      0.52      0.33     46400\n",
            "weighted avg       0.29      0.38      0.32     46400\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[15864   996     0]\n",
            " [ 1026  1690     0]\n",
            " [ 2940 23884     0]]\n",
            "(11600, 3) (11600,)\n",
            "(11600,) (11600,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.94      0.87      4346\n",
            "           1       0.07      0.62      0.13       795\n",
            "           2       0.00      0.00      0.00      6459\n",
            "\n",
            "    accuracy                           0.40     11600\n",
            "   macro avg       0.30      0.52      0.34     11600\n",
            "weighted avg       0.31      0.40      0.34     11600\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[4092  254    0]\n",
            " [ 305  490    0]\n",
            " [ 629 5830    0]]\n",
            "Epoch 3/3\n",
            "58/58 [==============================] - 56s 972ms/step - loss: 0.0780 - accuracy: 0.3869 - val_loss: 4.4591 - val_accuracy: 0.4046\n",
            "here\n",
            "(46400, 3) (46400,)\n",
            "(46400,) (46400,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.97      0.86     16860\n",
            "           1       0.06      0.56      0.11      2716\n",
            "           2       0.00      0.00      0.00     26824\n",
            "\n",
            "    accuracy                           0.39     46400\n",
            "   macro avg       0.28      0.51      0.32     46400\n",
            "weighted avg       0.29      0.39      0.32     46400\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[16385   475     0]\n",
            " [ 1196  1520     0]\n",
            " [ 3494 23330     0]]\n",
            "(11600, 3) (11600,)\n",
            "(11600,) (11600,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.97      0.88      4346\n",
            "           1       0.07      0.58      0.13       795\n",
            "           2       0.00      0.00      0.00      6459\n",
            "\n",
            "    accuracy                           0.40     11600\n",
            "   macro avg       0.29      0.52      0.34     11600\n",
            "weighted avg       0.31      0.40      0.34     11600\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[4232  114    0]\n",
            " [ 334  461    0]\n",
            " [ 709 5750    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8e57eb550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCW9DwvUS7v6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}