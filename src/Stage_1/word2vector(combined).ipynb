{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vector(combined).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yPdGW9l4ure"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "KnaflCTx44W-",
        "outputId": "aedf7b1b-ddbb-4678-935f-2286c3d78f3f"
      },
      "source": [
        "os.chdir(\"drive/My Drive/Thesis\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-4e3d1e6931b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/My Drive/Thesis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/Thesis'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS7Yh1ZL4K4r"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9qdgeZp4QAL"
      },
      "source": [
        "pre_model = KeyedVectors.load_word2vec_format('w2v/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_DWiDIa6qhG"
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rab0xDOnHdrP",
        "outputId": "90bd022c-0f1b-43c7-a823-6e7ea279b4c6"
      },
      "source": [
        "if 'hello' in pre_model:\n",
        "  print('Hello')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgcJn4Dv5Cw1"
      },
      "source": [
        "import json\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB3TdnI25PJM"
      },
      "source": [
        "raw_text = []\n",
        "raw_label = []\n",
        "with open('training.json') as f:\n",
        "  file = json.load(f)\n",
        "  f.close()\n",
        "for x in file:\n",
        "  raw_text.append(x['text'])\n",
        "  raw_label.append(x['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Lxf8SgKrOS"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plDp7Ulc6VTG"
      },
      "source": [
        "sequence_length = 100 # tune it to max 300\n",
        "\n",
        "def wv_input(text_list, label_list):\n",
        "  input_id_list = []\n",
        "  attention_mask_list = []\n",
        "  tag_list = []\n",
        "  for sentence, stripe in zip(text_list, label_list):\n",
        "    temp_token = []\n",
        "    temp_tag = []\n",
        "    temp_attention = []\n",
        "    temp_type = []\n",
        "    for word, tag in zip(sentence.split(), stripe):\n",
        "      #if tag == 2:\n",
        "        #tag = 0\n",
        "      if word in string.punctuation:\n",
        "        continue\n",
        "     # print('here')\n",
        "      if word in pre_model:\n",
        "        new_token = [pre_model[word]]\n",
        "        new_label = [tag] \n",
        "        new_attention = [1]\n",
        "      else:\n",
        "        new_token = [np.array([-1.0 for i in range(300)])]\n",
        "        new_label = [tag]\n",
        "        new_attention = [1]\n",
        "      \n",
        "      temp_token.extend(new_token)\n",
        "      temp_tag.extend(new_label)\n",
        "      temp_attention.extend(new_attention)\n",
        "   ## print(np.shape(temp_token))\n",
        "   # print(temp_token)\n",
        "\n",
        "\n",
        "    if len(temp_token) < sequence_length:\n",
        "      extend_list = [[-1.00 for i in range(300)]] * (sequence_length - len(temp_token))\n",
        "      extend_tag = [3] * (sequence_length - len(temp_token))\n",
        "      temp_attention = temp_attention + [0] * (sequence_length - len(temp_token))\n",
        "      temp_token = temp_token + extend_list\n",
        "      temp_tag = temp_tag + extend_tag\n",
        "\n",
        "    elif len(temp_token) > sequence_length:\n",
        "      temp_token = temp_token[:sequence_length ]\n",
        "      temp_attention = temp_attention[:sequence_length]\n",
        "      temp_tag = temp_tag[:sequence_length]\n",
        "\n",
        "    input_id_list.append(temp_token)\n",
        "    attention_mask_list.append(temp_attention)\n",
        "    tag_list.append(temp_tag)\n",
        "\n",
        "  \n",
        "  \n",
        "  return np.array(input_id_list), np.array(attention_mask_list), np.array(tag_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhcy2cv8KaLL"
      },
      "source": [
        "input_data, mask_data, output_data  = wv_input(raw_text, raw_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-vWjObkLhSY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-cpuwPLKmMY",
        "outputId": "b5cc7d39-b234-4306-a90f-13c170333003"
      },
      "source": [
        "np.shape(input_data), np.shape(output_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((580, 100, 300), (580, 100))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-SQDZFJO_oS"
      },
      "source": [
        "train_data_x = np.array(input_data[:464])\n",
        "valid_data_x = np.array(input_data[464:])                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCmug7NFPPnB"
      },
      "source": [
        "train_data_y = np.array(output_data[:464]).reshape(464, 100, 1)\n",
        "valid_data_y = np.array(output_data[464:]).reshape(116, 100, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INrU4rL3YKyl"
      },
      "source": [
        "train_mask = np.array(mask_data[:464])\n",
        "valid_mask = np.array(mask_data[464:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzgzzkA7RaJy"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEWfKWajRgUx"
      },
      "source": [
        "best = 0\n",
        "batch_count = 0\n",
        "num_label = 4\n",
        "def see(ty, tp):\n",
        "  #model.load('')\n",
        "  ty = ty.reshape(-1)\n",
        "  tp = tp.reshape(-1, num_label)\n",
        "  #print(tp.shape, ty.shape)\n",
        "  tp = [np.argmax(x) for x in tp]\n",
        "  dix = np.where(ty == (num_label - 1))[0]\n",
        "  tp = np.delete(tp, dix)\n",
        "  ty = np.delete(ty, dix)\n",
        "  #valid_p = [1 if x > 0.5 else 0 for x in model.predict(valid_x)]\n",
        "  #valid_p = model.predict(valid_x)\n",
        " # print(np.shape(tp), ty.shape)\n",
        "  print('\\nClassification Report \\n\\n')\n",
        "  \n",
        "  f = classification_report(ty, tp)\n",
        "  print(f)\n",
        " # print('\\nPrint Confusion Matrix \\n\\n')\n",
        "  print(confusion_matrix(ty, tp))\n",
        "  return f1_score(ty, tp, average=None)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9piFpZqRjm5"
      },
      "source": [
        "class mcb(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, log=None):\n",
        "   # global train_x, train_y, valid_x, valid_y\n",
        "    print('here')\n",
        "    _y = self.model.predict(train_data_x)\n",
        "    see(train_data_y, _y)\n",
        "    _y = self.model.predict(valid_data_x)\n",
        "    see(valid_data_y, _y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qt1asEqRm0R"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.LSTM(units=512, return_sequences=True),\n",
        "                             tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
        "                             tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation='relu')),\n",
        "                             tf.keras.layers.Dense(1024, activation='relu'),\n",
        "                             tf.keras.layers.Dense(4, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjjHd5tsRrKl"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U23pbRxKRuGi",
        "outputId": "bea7955f-2733-4450-8cf7-d42394ae3a29"
      },
      "source": [
        "model.fit(train_data_x, train_data_y, epochs=3,\n",
        "          validation_data=(valid_data_x, valid_data_y),\n",
        "          sample_weight=train_mask, callbacks=[mcb()],\n",
        "          batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "58/58 [==============================] - 61s 1s/step - loss: 0.3615 - accuracy: 0.2872 - val_loss: 3.7179 - val_accuracy: 0.2997\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(46400,) (46400,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.94      0.82     13690\n",
            "           1       0.00      0.00      0.00      3170\n",
            "           2       0.03      0.35      0.06      2716\n",
            "           3       0.00      0.00      0.00     26824\n",
            "\n",
            "    accuracy                           0.30     46400\n",
            "   macro avg       0.19      0.32      0.22     46400\n",
            "weighted avg       0.22      0.30      0.25     46400\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[12900     0   790     0]\n",
            " [ 2984     0   186     0]\n",
            " [ 1774     0   942     0]\n",
            " [  168     0 26656     0]]\n",
            "(11600, 4) (11600,)\n",
            "(11600,) (11600,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.94      0.80      3417\n",
            "           1       0.00      0.00      0.00       929\n",
            "           2       0.04      0.33      0.07       795\n",
            "           3       0.00      0.00      0.00      6459\n",
            "\n",
            "    accuracy                           0.30     11600\n",
            "   macro avg       0.18      0.32      0.22     11600\n",
            "weighted avg       0.21      0.30      0.24     11600\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[3213    0  204    0]\n",
            " [ 867    0   62    0]\n",
            " [ 531    0  264    0]\n",
            " [  45    0 6414    0]]\n",
            "Epoch 2/3\n",
            "58/58 [==============================] - 54s 930ms/step - loss: 0.2622 - accuracy: 0.2987 - val_loss: 4.1987 - val_accuracy: 0.3279\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(46400,) (46400,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.96      0.85     13690\n",
            "           1       0.75      0.01      0.02      3170\n",
            "           2       0.06      0.66      0.11      2716\n",
            "           3       0.00      0.00      0.00     26824\n",
            "\n",
            "    accuracy                           0.32     46400\n",
            "   macro avg       0.39      0.41      0.25     46400\n",
            "weighted avg       0.28      0.32      0.26     46400\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[13162    13   515     0]\n",
            " [ 2971    39   160     0]\n",
            " [  921     0  1795     0]\n",
            " [  281     0 26543     0]]\n",
            "(11600, 4) (11600,)\n",
            "(11600,) (11600,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.96      0.83      3417\n",
            "           1       0.50      0.01      0.02       929\n",
            "           2       0.07      0.66      0.13       795\n",
            "           3       0.00      0.00      0.00      6459\n",
            "\n",
            "    accuracy                           0.33     11600\n",
            "   macro avg       0.33      0.41      0.24     11600\n",
            "weighted avg       0.26      0.33      0.25     11600\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[3270    8  139    0]\n",
            " [ 881    8   40    0]\n",
            " [ 269    0  526    0]\n",
            " [  68    0 6391    0]]\n",
            "Epoch 3/3\n",
            "58/58 [==============================] - 53s 917ms/step - loss: 0.2083 - accuracy: 0.3262 - val_loss: 4.0479 - val_accuracy: 0.3439\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(46400,) (46400,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85     13690\n",
            "           1       0.62      0.56      0.59      3170\n",
            "           2       0.06      0.58      0.10      2716\n",
            "           3       0.00      0.00      0.00     26824\n",
            "\n",
            "    accuracy                           0.34     46400\n",
            "   macro avg       0.37      0.51      0.39     46400\n",
            "weighted avg       0.29      0.34      0.30     46400\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[12336  1062   292     0]\n",
            " [ 1300  1770   100     0]\n",
            " [ 1134    10  1572     0]\n",
            " [  432     0 26392     0]]\n",
            "(11600, 4) (11600,)\n",
            "(11600,) (11600,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83      3417\n",
            "           1       0.62      0.57      0.59       929\n",
            "           2       0.06      0.56      0.12       795\n",
            "           3       0.00      0.00      0.00      6459\n",
            "\n",
            "    accuracy                           0.34     11600\n",
            "   macro avg       0.37      0.50      0.38     11600\n",
            "weighted avg       0.28      0.34      0.30     11600\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[3016  322   79    0]\n",
            " [ 382  529   18    0]\n",
            " [ 347    4  444    0]\n",
            " [ 113    0 6346    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9b50b5ed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCW9DwvUS7v6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}