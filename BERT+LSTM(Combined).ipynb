{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT+LSTM(Combined).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQNgVhcbi8Ra",
        "outputId": "1b7eae05-4c82-4cd9-f640-6446dc4f820c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuP7W235jDDf"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Ts7xQQjQ87"
      },
      "source": [
        "###Setting path to working directory\n",
        "Directory contains the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts94SjPDjIY4"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Thesis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO5sLfShjj70",
        "outputId": "9e9002b8-3552-41be-d222-5c0424ca3855"
      },
      "source": [
        "!pip install -q tf-models-official==2.3.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 849kB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 88kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 35.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 39.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 43.0MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBE9aGc1jshh"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import official.nlp.bert.tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5cNf9N2jywb"
      },
      "source": [
        "##Initiating Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_0YpqVljw4A"
      },
      "source": [
        "tkn = official.nlp.bert.tokenization.FullTokenizer(vocab_file=\"vocab.txt\", \n",
        "                                                   do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXEIzFBmpZ5w"
      },
      "source": [
        "mybert = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_wwm_cased_L-24_H-1024_A-16/3\",\n",
        "    trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QB0sSqXlM5N"
      },
      "source": [
        "##Preparing BERT INPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYljOolDlaEd"
      },
      "source": [
        "### loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b57-6E2ZlcRa"
      },
      "source": [
        "import json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgV3l-ltliYK"
      },
      "source": [
        "raw_text = []\n",
        "raw_label = []\n",
        "with open('training.json') as f:\n",
        "  file = json.load(f)\n",
        "  f.close()\n",
        "for x in file:\n",
        "  raw_text.append(x['text'])\n",
        "  raw_label.append(x['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwSnCdHpl-LN"
      },
      "source": [
        "###Formatting DATA for BERT\n",
        "NB: Tune the sequnce length here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTzJTodTmBk2"
      },
      "source": [
        "sequence_length = 100 # tune it to max 600\n",
        "etag = 3\n",
        "ftag = 2\n",
        "def bert_input(text_list, label_list):\n",
        "  input_id_list = []\n",
        "  attention_mask_list = []\n",
        "  input_type_list = []\n",
        "  tag_list = []\n",
        "  max_length = 320\n",
        "  for sentence, stripe in zip(text_list, label_list):\n",
        "    temp_token = []\n",
        "    temp_tag = []\n",
        "    temp_attention = []\n",
        "    temp_type = []\n",
        "    for word, tag in zip(sentence.split(), stripe):\n",
        "      #if tag == 1:\n",
        "      #  tag = 0\n",
        "      #elif tag == 2:\n",
        "      #  tag = 1\n",
        "      new_token = tkn.tokenize(word)\n",
        "      new_token = tkn.convert_tokens_to_ids(new_token)\n",
        "      new_label = [tag] + ( [ftag] * (len(new_token) - 1))\n",
        "      new_attention = [1] * len(new_token)\n",
        "      new_type =  [0] * len(new_token)\n",
        "      \n",
        "      temp_token.extend(new_token)\n",
        "      temp_tag.extend(new_label)\n",
        "      temp_attention.extend(new_attention)\n",
        "      temp_type.extend(new_type)\n",
        "    \n",
        "    temp_token = [101] + temp_token + [102]\n",
        "    temp_tag = [0] + temp_tag + [0]\n",
        "    temp_attention = [1] + temp_attention + [1]\n",
        "    temp_type = [0] + temp_type + [0]\n",
        "\n",
        "    if len(temp_token) < sequence_length:\n",
        "      extend_list = [0] * (sequence_length - len(temp_token))\n",
        "      extend_tag = [etag] * (sequence_length - len(temp_token))\n",
        "      temp_token = temp_token + extend_list\n",
        "      temp_attention = temp_attention + extend_list\n",
        "      temp_type = temp_type + extend_list\n",
        "      temp_tag = temp_tag + extend_tag\n",
        "\n",
        "    elif len(temp_token) > sequence_length:\n",
        "      temp_token = temp_token[:sequence_length - 1] + [102]\n",
        "      temp_attention = temp_attention[:sequence_length]\n",
        "      temp_tag = temp_tag[:sequence_length - 1] + [0]\n",
        "      temp_type = temp_type[:sequence_length]\n",
        "    \n",
        "    #temp_tag = temp_tag + extend_tag\n",
        "    #print(temp_attention)\n",
        "    input_id_list.append(tf.constant(temp_token))\n",
        "    input_type_list.append(tf.constant(temp_type))\n",
        "    attention_mask_list.append(tf.constant(temp_attention))\n",
        "    tag_list.append(temp_tag)\n",
        "\n",
        "\n",
        "  #print(attention_mask_list)\n",
        "  #print(input_type_list)\n",
        "  dic = dict(\n",
        "    input_word_ids=input_id_list,\n",
        "    input_mask=attention_mask_list,\n",
        "    input_type_ids=input_type_list)\n",
        "  \n",
        "  return dic, tag_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJh5xpV_pEDM",
        "outputId": "d8e40643-bf58-40f6-8ce3-17cf876570e9"
      },
      "source": [
        "train_x, train_y, train_f1 = [], [], []\n",
        "for x, y in zip(raw_text[:232], raw_label[:232]):\n",
        "  a, b = bert_input([x], [y])\n",
        "  train_f1.append(a['input_mask'][0])\n",
        "  a = mybert(a)['sequence_output'][0]\n",
        "  b = b[0]\n",
        "  train_x.append(np.array(a))\n",
        "  train_y.append(np.array(b))\n",
        "  #break\n",
        "train_x = np.array(train_x)\n",
        "train_y = np.array(train_y)\n",
        "train_f1 = np.array(train_f1)\n",
        "train_x.shape, train_y.shape, train_f1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((232, 100, 1024), (232, 100), (232, 100))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd5gld2FqA8f",
        "outputId": "19df92c3-e0ff-46b1-a242-6c5fe77e7555"
      },
      "source": [
        "train_x2, train_y2, train_f2 = [], [], []\n",
        "for x, y in zip(raw_text[232:464], raw_label[232:464]):\n",
        "  a, b = bert_input([x], [y])\n",
        "  train_f2.append(a['input_mask'][0])\n",
        "  a = mybert(a)['sequence_output'][0]\n",
        "  b = b[0]\n",
        "  train_x2.append(np.array(a))\n",
        "  train_y2.append(np.array(b))\n",
        "  #break\n",
        "print('I am here')\n",
        "train_x2 = np.array(train_x2)\n",
        "train_y2 = np.array(train_y2)\n",
        "train_f2 = np.array(train_f2)\n",
        "train_x2.shape, train_y2.shape, train_f2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am here\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((232, 100, 1024), (232, 100), (232, 100))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdiEjVXNqKGa"
      },
      "source": [
        "train_x = np.concatenate((train_x, train_x2))\n",
        "train_y = np.concatenate((train_y, train_y2))\n",
        "train_f = np.concatenate((train_f1, train_f2))\n",
        "train_y = np.expand_dims(train_y, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdc3PTtpqNG8",
        "outputId": "72f6bae0-9321-4044-a125-de48587e0c6c"
      },
      "source": [
        "\n",
        "valid_x, valid_y, valid_f = [], [], []\n",
        "for x, y in zip(raw_text[464:], raw_label[464:]):\n",
        "  a, b = bert_input([x], [y])\n",
        "  valid_f.append(a['input_mask'][0])\n",
        "  a = mybert(a)['sequence_output'][0]\n",
        "  b = b[0]\n",
        "  valid_x.append(np.array(a))\n",
        "  valid_y.append(np.array(b))\n",
        "  \n",
        "  #break\n",
        "print('I am here')\n",
        "valid_x = np.array(valid_x)\n",
        "valid_y = np.array(valid_y)\n",
        "valid_f = np.array(valid_f)\n",
        "valid_y = np.expand_dims(valid_y, axis=-1)\n",
        "valid_x.shape, valid_y.shape, valid_f.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am here\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((116, 100, 1024), (116, 100, 1), (116, 100))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHTQ_WKZxX4_"
      },
      "source": [
        "##ModeL Creation\n",
        "##Tuning List\n",
        "\n",
        "\n",
        "1.   Epoch\n",
        "2.   Layer Number\n",
        "3. Neuron units\n",
        "4. batch size\n",
        "5. sequence Length\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-SekTJ4yKhU"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQZtLzwgqPsh"
      },
      "source": [
        "best = 0\n",
        "num_label = 5\n",
        "def see(ty, tp):\n",
        "  #model.load('')\n",
        "  ty = ty.reshape(-1)\n",
        "  tp = tp.reshape(-1, num_label)\n",
        "  print(tp.shape, ty.shape)\n",
        "  tp = [np.argmax(x) for x in tp]\n",
        "  dix = np.where(ty == (num_label - 1))[0]\n",
        "  tp = np.delete(tp, dix)\n",
        "  ty = np.delete(ty, dix)\n",
        "  #valid_p = [1 if x > 0.5 else 0 for x in model.predict(valid_x)]\n",
        "  #valid_p = model.predict(valid_x)\n",
        "  print(np.shape(tp), ty.shape)\n",
        "  print('\\nClassification Report \\n\\n')\n",
        "  \n",
        "  f = classification_report(ty, tp)\n",
        "  print(f)\n",
        "  print('\\nPrint Confusion Matrix \\n\\n')\n",
        "  print(confusion_matrix(ty, tp))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ni5oyGisWWx"
      },
      "source": [
        "class mcb(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, log=None):\n",
        "   # global train_x, train_y, valid_x, valid_y\n",
        "    print('here')\n",
        "    _y = self.model.predict(train_x)\n",
        "    see(train_y, _y)\n",
        "    _y = self.model.predict(valid_x)\n",
        "    see(valid_y, _y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEuuzZGeslKU"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.LSTM(units=1024, return_sequences=True),\n",
        "                             tf.keras.layers.LSTM(units=1024, return_sequences=True),\n",
        "                             tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1024, activation='relu')),\n",
        "                             tf.keras.layers.Dense(256, activation='relu'),\n",
        "                             tf.keras.layers.Dense(num_label, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8YZFc1WzMN4"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnKYlmlWzTas",
        "outputId": "c2235164-1364-4151-9424-44a4a02768c8"
      },
      "source": [
        "model.fit(train_x, train_y, epochs=15,\n",
        "          validation_data=(valid_x, valid_y),\n",
        "          sample_weight=train_f, callbacks=[mcb()],\n",
        "          batch_size=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "  6/464 [..............................] - ETA: 1:00 - loss: 0.5240 - accuracy: 0.3660WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0148s vs `on_train_batch_end` time: 0.1031s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0148s vs `on_train_batch_end` time: 0.1031s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "464/464 [==============================] - 72s 146ms/step - loss: 0.2796 - accuracy: 0.4685 - val_loss: 4.6094 - val_accuracy: 0.5778\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97     20601\n",
            "           1       0.84      0.85      0.84      3212\n",
            "           2       0.99      0.99      0.99      2234\n",
            "\n",
            "    accuracy                           0.96     26047\n",
            "   macro avg       0.94      0.94      0.94     26047\n",
            "weighted avg       0.96      0.96      0.96     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20074   515    12]\n",
            " [  486  2722     4]\n",
            " [   18     4  2212]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      5465\n",
            "           1       0.84      0.81      0.82       938\n",
            "           2       0.98      0.99      0.99       635\n",
            "\n",
            "    accuracy                           0.95      7038\n",
            "   macro avg       0.93      0.92      0.93      7038\n",
            "weighted avg       0.95      0.95      0.95      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5314  148    3]\n",
            " [ 169  761    8]\n",
            " [   6    1  628]]\n",
            "Epoch 2/15\n",
            "464/464 [==============================] - 67s 144ms/step - loss: 0.0662 - accuracy: 0.5248 - val_loss: 4.6185 - val_accuracy: 0.5779\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     20601\n",
            "           1       0.97      0.84      0.90      3212\n",
            "           2       0.99      1.00      0.99      2234\n",
            "\n",
            "    accuracy                           0.98     26047\n",
            "   macro avg       0.98      0.95      0.96     26047\n",
            "weighted avg       0.98      0.98      0.98     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20494    91    16]\n",
            " [  492  2708    12]\n",
            " [    2     0  2232]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      5465\n",
            "           1       0.90      0.73      0.81       938\n",
            "           2       0.98      1.00      0.99       635\n",
            "\n",
            "    accuracy                           0.95      7038\n",
            "   macro avg       0.95      0.90      0.92      7038\n",
            "weighted avg       0.95      0.95      0.95      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5384   74    7]\n",
            " [ 243  687    8]\n",
            " [   2    0  633]]\n",
            "Epoch 3/15\n",
            "464/464 [==============================] - 67s 144ms/step - loss: 0.0365 - accuracy: 0.5430 - val_loss: 5.0298 - val_accuracy: 0.5795\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     20601\n",
            "           1       0.90      0.96      0.93      3212\n",
            "           2       0.99      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           0.98     26047\n",
            "   macro avg       0.96      0.98      0.97     26047\n",
            "weighted avg       0.98      0.98      0.98     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20265   332     4]\n",
            " [  110  3094     8]\n",
            " [    1     0  2233]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      5465\n",
            "           1       0.81      0.88      0.84       938\n",
            "           2       0.99      1.00      0.99       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.93      0.95      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5263  198    4]\n",
            " [ 110  826    2]\n",
            " [   2    0  633]]\n",
            "Epoch 4/15\n",
            "464/464 [==============================] - 67s 144ms/step - loss: 0.0253 - accuracy: 0.5456 - val_loss: 5.7452 - val_accuracy: 0.5814\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     20601\n",
            "           1       0.97      0.97      0.97      3212\n",
            "           2       0.99      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           0.99     26047\n",
            "   macro avg       0.99      0.99      0.99     26047\n",
            "weighted avg       0.99      0.99      0.99     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20492   102     7]\n",
            " [   82  3117    13]\n",
            " [    0     1  2233]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      5465\n",
            "           1       0.86      0.83      0.84       938\n",
            "           2       0.99      1.00      0.99       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.94      0.93      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5337  123    5]\n",
            " [ 159  775    4]\n",
            " [   3    0  632]]\n",
            "Epoch 5/15\n",
            "464/464 [==============================] - 67s 144ms/step - loss: 0.0210 - accuracy: 0.5497 - val_loss: 7.7291 - val_accuracy: 0.5825\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       0.99      0.97      0.98      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           0.99     26047\n",
            "   macro avg       0.99      0.99      0.99     26047\n",
            "weighted avg       0.99      0.99      0.99     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20560    41     0]\n",
            " [   81  3131     0]\n",
            " [    6     4  2224]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      5465\n",
            "           1       0.89      0.80      0.84       938\n",
            "           2       1.00      0.99      1.00       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.95      0.93      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5371   92    2]\n",
            " [ 183  755    0]\n",
            " [   2    2  631]]\n",
            "Epoch 6/15\n",
            "464/464 [==============================] - 67s 144ms/step - loss: 0.0103 - accuracy: 0.5594 - val_loss: 9.5702 - val_accuracy: 0.5845\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       0.99      0.99      0.99      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       1.00      1.00      1.00     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20577    22     2]\n",
            " [   24  3183     5]\n",
            " [    0     0  2234]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      5465\n",
            "           1       0.92      0.80      0.86       938\n",
            "           2       0.98      1.00      0.99       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.96      0.93      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5394   65    6]\n",
            " [ 182  752    4]\n",
            " [   1    0  634]]\n",
            "Epoch 7/15\n",
            "464/464 [==============================] - 67s 144ms/step - loss: 0.0079 - accuracy: 0.5529 - val_loss: 9.3873 - val_accuracy: 0.5827\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       0.99      0.98      0.99      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       1.00      0.99      0.99     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20581    19     1]\n",
            " [   71  3141     0]\n",
            " [    2     2  2230]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      5465\n",
            "           1       0.90      0.79      0.84       938\n",
            "           2       1.00      1.00      1.00       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.95      0.92      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5383   81    1]\n",
            " [ 195  742    1]\n",
            " [   1    0  634]]\n",
            "Epoch 8/15\n",
            "464/464 [==============================] - 67s 144ms/step - loss: 0.0117 - accuracy: 0.5361 - val_loss: 8.3231 - val_accuracy: 0.5798\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       0.98      1.00      0.99      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       0.99      1.00      0.99     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20537    63     1]\n",
            " [   14  3197     1]\n",
            " [    3     5  2226]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      5465\n",
            "           1       0.84      0.83      0.84       938\n",
            "           2       0.99      0.99      0.99       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.93      0.93      0.93      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5316  147    2]\n",
            " [ 155  781    2]\n",
            " [   4    2  629]]\n",
            "Epoch 9/15\n",
            "464/464 [==============================] - 67s 145ms/step - loss: 0.0146 - accuracy: 0.5663 - val_loss: 11.2640 - val_accuracy: 0.5835\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       1.00      0.99      1.00      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       1.00      1.00      1.00     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20595     6     0]\n",
            " [   17  3195     0]\n",
            " [    0     1  2233]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      5465\n",
            "           1       0.89      0.82      0.85       938\n",
            "           2       1.00      0.99      0.99       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.95      0.93      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5374   89    2]\n",
            " [ 170  767    1]\n",
            " [   5    2  628]]\n",
            "Epoch 10/15\n",
            "464/464 [==============================] - 67s 145ms/step - loss: 0.0022 - accuracy: 0.5712 - val_loss: 13.5490 - val_accuracy: 0.5847\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       0.99      1.00      1.00      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       1.00      1.00      1.00     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20585    16     0]\n",
            " [    6  3205     1]\n",
            " [    1     2  2231]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      5465\n",
            "           1       0.90      0.82      0.86       938\n",
            "           2       1.00      1.00      1.00       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.96      0.93      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5380   84    1]\n",
            " [ 167  769    2]\n",
            " [   2    0  633]]\n",
            "Epoch 11/15\n",
            "464/464 [==============================] - 67s 145ms/step - loss: 0.0019 - accuracy: 0.5610 - val_loss: 14.0971 - val_accuracy: 0.5810\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       1.00      0.97      0.98      3212\n",
            "           2       0.98      1.00      0.99      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       0.99      0.99      0.99     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20586     9     6]\n",
            " [   57  3125    30]\n",
            " [    0     0  2234]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      5465\n",
            "           1       0.92      0.76      0.83       938\n",
            "           2       0.96      1.00      0.98       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.95      0.92      0.93      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5391   65    9]\n",
            " [ 208  714   16]\n",
            " [   0    0  635]]\n",
            "Epoch 12/15\n",
            "464/464 [==============================] - 67s 145ms/step - loss: 0.0053 - accuracy: 0.5457 - val_loss: 13.0588 - val_accuracy: 0.5842\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       1.00      1.00      1.00      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       1.00      1.00      1.00     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20596     5     0]\n",
            " [    8  3204     0]\n",
            " [    0     1  2233]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      5465\n",
            "           1       0.92      0.79      0.85       938\n",
            "           2       0.99      1.00      1.00       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.96      0.93      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5400   64    1]\n",
            " [ 193  742    3]\n",
            " [   0    0  635]]\n",
            "Epoch 13/15\n",
            "464/464 [==============================] - 67s 145ms/step - loss: 0.0018 - accuracy: 0.5481 - val_loss: 12.8364 - val_accuracy: 0.5814\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       0.99      0.99      0.99      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       1.00      1.00      1.00     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20582    18     1]\n",
            " [   16  3194     2]\n",
            " [    0     0  2234]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      5465\n",
            "           1       0.86      0.83      0.84       938\n",
            "           2       0.99      0.99      0.99       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.94      0.93      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5339  124    2]\n",
            " [ 157  775    6]\n",
            " [   5    0  630]]\n",
            "Epoch 14/15\n",
            "464/464 [==============================] - 67s 145ms/step - loss: 0.0024 - accuracy: 0.5399 - val_loss: 13.7734 - val_accuracy: 0.5828\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       1.00      1.00      1.00      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       1.00      1.00      1.00     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20596     5     0]\n",
            " [   16  3196     0]\n",
            " [    0     1  2233]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      5465\n",
            "           1       0.90      0.80      0.85       938\n",
            "           2       0.99      0.99      0.99       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.95      0.93      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5381   83    1]\n",
            " [ 185  749    4]\n",
            " [   3    2  630]]\n",
            "Epoch 15/15\n",
            "464/464 [==============================] - 67s 145ms/step - loss: 0.0025 - accuracy: 0.5649 - val_loss: 11.8537 - val_accuracy: 0.5841\n",
            "here\n",
            "(46400, 4) (46400,)\n",
            "(26047,) (26047,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     20601\n",
            "           1       1.00      0.99      0.99      3212\n",
            "           2       1.00      1.00      1.00      2234\n",
            "\n",
            "    accuracy                           1.00     26047\n",
            "   macro avg       1.00      0.99      1.00     26047\n",
            "weighted avg       1.00      1.00      1.00     26047\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[20588    11     2]\n",
            " [   40  3171     1]\n",
            " [    6     0  2228]]\n",
            "(11600, 4) (11600,)\n",
            "(7038,) (7038,)\n",
            "\n",
            "Classification Report \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      5465\n",
            "           1       0.92      0.80      0.86       938\n",
            "           2       0.99      0.99      0.99       635\n",
            "\n",
            "    accuracy                           0.96      7038\n",
            "   macro avg       0.96      0.92      0.94      7038\n",
            "weighted avg       0.96      0.96      0.96      7038\n",
            "\n",
            "\n",
            "Print Confusion Matrix \n",
            "\n",
            "\n",
            "[[5400   64    1]\n",
            " [ 184  749    5]\n",
            " [   7    1  627]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0cdd11a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olZh-fk1zh60"
      },
      "source": [
        "a = np.array([[[1, 2], [3, 4], [5, 6]], [[1, 2], [3, 4], [5, 6]]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ8nUQSH3xWR",
        "outputId": "113c7f65-7ae0-4e46-fde8-1f47802b71af"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNz2zLTR343F",
        "outputId": "e522f1d9-ac75-4aae-f422-266ed8dd3daf"
      },
      "source": [
        "a.reshape(-1, 2).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J5KwDGcDAXR"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBfe_l9937LZ"
      },
      "source": [
        "ar = np.array([4, 2, 3, 4, 5, 6, 7, 4, 79, 10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kTpbBDHDFir",
        "outputId": "f112d304-9c85-4384-e533-a5d4736e36f7"
      },
      "source": [
        "np.delete(ar, np.where(ar == 4)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  3,  5,  6,  7, 79, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4kscgzfDDgu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}